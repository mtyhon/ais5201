

<!DOCTYPE html>


<html data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>The Physics Informed Neural Network &#8212; AIS 5201: AI In Astrophysics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter3/tabular-5';</script>
    <link rel="canonical" href="https://USER.github.io/REPO/chapter3/tabular-5.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Images" href="../chapter4/section_intro.html" />
    <link rel="prev" title="Catalogue Data Part 2: Finding Clusters and Overdensities" href="tabular-4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">AIS 5201: AI In Astrophysics</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction to AIS 5201
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter1/section_intro.html">Time-domain Data</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/fitting_power_spectrum_1.html">Fitting Red Giant Oscillations Part 1: <em>Traditional Optimization</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/fitting_power_spectrum_2.html">Fitting Red Giant Oscillations Part 2: <em>Flows &amp; Simulation-Based Inference</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/ps_statistics.html"><em>Power Spectrum Statistics</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/eb-morphology_1.html">Eclipse Morphology Part 1: <em>Exploring and Preparing Data</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/eb-morphology_2.html">Eclipse Morphology Part 2: <em>Low-Dimensional Representations</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/eb-morphology_3.html">Eclipse Morphology Part 3: <em>Latent Spaces and Visualizing Them</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/eb-morphology_4.html">Eclipse Morphology Part 4: <em>The Variational Autoencoder</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/transit-1.html">Planetary Transits Part 1: <em>Observing Transits</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/transit-2.html">Planetary Transits Part 2: <em>Classifying Transits</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter1/transit-3.html">Planetary Transits Part 3: <em>Fitting a Transit Profile</em></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter2/section_intro.html">Spectra</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/sed-1.html">Spectral Energy Distribution (SED) Part 1: <em>Observing SEDs</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/sed-2.html">Spectral Energy Distribution (SED) Part 2: <em>Fitting SEDs</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/sed-3.html">Spectral Energy Distribution (SED) Part 3: <em>Bayesian Evidence and Model Selection</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/spectra-1.html">Stellar Spectra Part 1: <em>Observing Detailed Spectral Features</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/spectra-2.html">Stellar Spectra Part 2: <em>The Cannon</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/spectra-3.html">Stellar Spectra Part 3: <em>The Payne</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/spectra-4.html">Stellar Spectra Part 4: <em>Detecting Stellar Activity Indicators</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter2/spectra-5.html">Stellar Spectra Part 5: <em>Domain Transfer</em></a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="section_intro.html">Tabular Data</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tabular-1.html">Grids of Stellar Models Part 1: <em>Stellar Parameter Regression</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="tabular-2.html">Grids of Stellar Models Part 2: <em>Interpolation</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="tabular-3.html">Catalogue Data Part 1: <em>Mixed Data Types</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="tabular-4.html">Catalogue Data Part 2: <em>Finding Clusters and Overdensities</em></a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#"><em>The Physics Informed Neural Network</em></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter4/section_intro.html">Images</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/images-1.html">Images Part 1: <em>Galaxy Merger Classification</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/images-2.html">Images Part 2: <em>Galaxy Morphology Classification</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/images-3.html">Images Part 3: <em>Self-Supervised Learning</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/images-4.html">Images Part 4: <em>Upscaling the Cosmic Web</em></a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/docs/chapter3/tabular-5.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/edit/master/docs/chapter3/tabular-5.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fchapter3/tabular-5.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter3/tabular-5.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Physics Informed Neural Network</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formulation">Formulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-the-lane-emden-equation">Example: The Lane-Emden Equation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-lane-emden-equations">Generating Lane-Emden Equations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-pinn">Training the PINN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-a-generator">Setting up a Generator</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-networks">Defining the Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losses-physics-constraint">Losses – Physics Constraint</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losses-boundary-conditions">Losses – Boundary Conditions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-loop">Training Loop</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-odes-in-astrophysics">Other ODEs in Astrophysics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1-planetary-motion">Example 1 - Planetary Motion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-friedmann-acceleration-equation">Example 2 - Friedmann Acceleration Equation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-physics-informed-neural-network">
<span id="content-references-tabular-part5"></span><h1><em>The Physics Informed Neural Network</em><a class="headerlink" href="#the-physics-informed-neural-network" title="Permalink to this headline">#</a></h1>
<p><em><strong>Author: Marc Hon (<a class="reference external" href="mailto:mtyhon&#37;&#52;&#48;nus&#46;edu&#46;sg">mtyhon<span>&#64;</span>nus<span>&#46;</span>edu<span>&#46;</span>sg</a>), Earl Patrick Bellinger (<a class="reference external" href="mailto:earl&#46;bellinger&#37;&#52;&#48;yale&#46;edu">earl<span>&#46;</span>bellinger<span>&#64;</span>yale<span>&#46;</span>edu</a>)</strong></em></p>
<p>Physics-Informed Neural Networks (PINNs) are neural networks that solves or approximates solutions to physical systems governed by differential equations, using prior physical knowledge (e.g., conservation laws, PDEs, ODEs) encoded <strong>directly</strong> into the loss function during training.</p>
<p>Rather than being purely data-driven like classical machine learning, PINNs are directly constrained to produce outputs consistent with physics.</p>
<section id="formulation">
<h2>Formulation<a class="headerlink" href="#formulation" title="Permalink to this headline">#</a></h2>
<p>A Physics-Informed Neural Network solves problems where the solution <span class="math notranslate nohighlight">\( u \)</span> must satisfy a differential equation of the form:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{F}\!\left(u(\boldsymbol{\xi}); \boldsymbol{\xi} \right) = 0,
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \boldsymbol{\xi} \in \mathbb{R}^d \)</span> denotes the independent variables (e.g., radius <span class="math notranslate nohighlight">\(r\)</span>, time <span class="math notranslate nohighlight">\(t\)</span>, orbital phase <span class="math notranslate nohighlight">\(\phi\)</span>, or frequency <span class="math notranslate nohighlight">\(\nu\)</span>),</p></li>
<li><p><span class="math notranslate nohighlight">\( u(\boldsymbol{\xi}) \)</span> is the unknown function to approximate,</p></li>
<li><p><span class="math notranslate nohighlight">\( \mathcal{F} \)</span> is a differential operator encoding the governing physical laws.</p></li>
</ul>
<p>A neural network <span class="math notranslate nohighlight">\( u_\theta(\boldsymbol{\xi}) \)</span> with parameters <span class="math notranslate nohighlight">\(\theta\)</span> is trained to minimize a composite loss involving the following:</p>
<p><strong>Data Loss</strong> (fitting observations):</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text{data}} = \frac{1}{N} \sum_{i=1}^{N} 
\big( u_\theta(\boldsymbol{\xi}_i) - u_i^{\text{obs}} \big)^2
\]</div>
</div></blockquote>
<p><strong>Physics Loss</strong> (enforcing the governing equations):</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text{physics}} = \frac{1}{M} \sum_{j=1}^{M}
\left( \mathcal{F}\!\left(u_\theta; \boldsymbol{\xi}_j\right) \right)^2
\]</div>
</div></blockquote>
<p>Many physical systems also require <strong>Boundary or Initial Conditions</strong> at a boundary  <span class="math notranslate nohighlight">\( \partial \Omega \)</span> in addition to the governing equations:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}\!\left(u(\boldsymbol{\xi})\right) = 0,
\qquad \boldsymbol{\xi} \in \partial \Omega, 
\]</div>
<p>such that</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text{bc}} =
\frac{1}{K} \sum_{k=1}^{K}
\left( \mathcal{B}(u_\theta; \boldsymbol{\xi}_k) \right)^2
\]</div>
</div></blockquote>
<p>Putting it altogether, we have</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[
\mathcal{L}(\theta) = 
\mathcal{L}_{\text{data}} + \lambda_{\text{phys}} \,\mathcal{L}_{\text{physics}} + \lambda_{\text{bc}} \,\mathcal{L}_{\text{bc}},
\]</div>
</div></blockquote>
<p>Here:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \{ (\boldsymbol{\xi}_i, u_i^{\text{obs}}) \} \)</span> are observation points,</p></li>
<li><p><span class="math notranslate nohighlight">\( \{ \boldsymbol{\xi}_j \} \)</span> are collocation points (chosen freely within the domain),</p></li>
<li><p><span class="math notranslate nohighlight">\( \lambda_{\text{phys}} \)</span> and <span class="math notranslate nohighlight">\(\lambda_{\text{bc}}\)</span> are weighting parameters balancing data fidelity and physical consistency for the physics and boundary loss, respectively.</p></li>
</ul>
<p>Here, <strong>automatic differentiation</strong> will be used to obtain the derivatives required in <span class="math notranslate nohighlight">\(\mathcal{F}\)</span>.</p>
</section>
<section id="example-the-lane-emden-equation">
<h2>Example: The Lane-Emden Equation<a class="headerlink" href="#example-the-lane-emden-equation" title="Permalink to this headline">#</a></h2>
<p>The Lane-Emden equation is a simplified model for the internal structure of the star, taking the form of</p>
<div class="math notranslate nohighlight" id="equation-eq-lane-emden">
<span class="eqno">(34)<a class="headerlink" href="#equation-eq-lane-emden" title="Permalink to this equation">#</a></span>\[\frac{1}{\xi^2} \frac{d}{d\xi} \left( \xi^2 \frac{d\theta}{d\xi} \right) + \theta^n = 0\]</div>
<p>with the following <strong>boundary conditions</strong>:</p>
<div class="math notranslate nohighlight" id="equation-boundary-lane-emden">
<span class="eqno">(35)<a class="headerlink" href="#equation-boundary-lane-emden" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{align}
\theta &amp;= 1 \quad \text{for} \quad \xi = 0 \\
d\theta/d\xi &amp;= 0 \quad \text{for} \quad \xi = 0,
\end{align}\end{split}\]</div>
<p>where the surface of the star is defined as <span class="math notranslate nohighlight">\(\xi_1\)</span>, where</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\theta &amp;= 0 \quad \text{for} \quad \xi = \xi_1.
\end{align}
\]</div>
<div class="tip admonition">
<p class="admonition-title">Physical Interpretation</p>
<p>The structures of stars are governed by the equations of stellar structure, The pressure <span class="math notranslate nohighlight">\(P\)</span> and density <span class="math notranslate nohighlight">\(\rho\)</span> in the interiors of stars are governed by the following ODEs in particular:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\frac{dP}{dm} &amp;= -\frac{Gm}{4\pi r^4} \quad \text{(hydrostatic equilibrium)}\\
\frac{dr}{dm} &amp;= -\frac{1}{4\pi r^2 \rho} \quad \text{(mass continuity)},
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(m\)</span> is the mass enclosed inside a shell of radius <span class="math notranslate nohighlight">\(r\)</span> within the star, and <span class="math notranslate nohighlight">\(G\)</span> is the gravitational constant.</p>
<p>The above equations can be solved in the case where <span class="math notranslate nohighlight">\(\rho\)</span> can be expressed as a function of <span class="math notranslate nohighlight">\(P\)</span> in the following form:</p>
<div class="math notranslate nohighlight">
\[
P = K\rho^{(1 + \frac{1}{n})},
\]</div>
<p>which are known as <strong>polytropic models</strong>, with <span class="math notranslate nohighlight">\(n\)</span> known as the <em>polytropic index</em>. Here, we introduce the dimensionless values</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\rho(r) &amp;= \rho_c \theta^n (r) \\
r &amp;= \alpha\xi, \quad \text{where} \quad \alpha^2 = \frac{(n+1)K\rho_c^{1/n - 1}}{4\pi G},
\end{align}
\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(\rho_c\)</span> being the central density of the star. The boundary conditions naturally arise from these parameterizations of <span class="math notranslate nohighlight">\(\rho\)</span> and <span class="math notranslate nohighlight">\(r\)</span> into <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\xi\)</span>, respectively.</p>
<p>Polytropes are widely used as simplified models of stellar and planetary interiors:</p>
<ul class="simple">
<li><p><strong><span class="math notranslate nohighlight">\(n = 0\)</span></strong>: Constant density (incompressible), first-order model for rocky planets.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(n \approx 0.5 – 1\)</span></strong>:  Models for neutron stars.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(n = 1.5\)</span></strong>:  Fully convective stars like brown dwarfs and gas giant planets, low-mass white dwarfs.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(n = 3\)</span></strong>: Massive white dwarfs, main-sequence stars in their radiation zone.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(n = 5\)</span></strong>: Infinite radius.</p></li>
</ul>
</div>
<section id="generating-lane-emden-equations">
<h3>Generating Lane-Emden Equations<a class="headerlink" href="#generating-lane-emden-equations" title="Permalink to this headline">#</a></h3>
<p>We want to solve the Lane-Emden Equation for a given polytropic index <span class="math notranslate nohighlight">\(n\)</span>. Analytical solutions exists for <span class="math notranslate nohighlight">\(n=1,3,5\)</span>, but for the other cases numerical integration is required. In the following, we will create a function that uses the <strong>predictor–corrector method</strong> for numerically solving the Lane–Emden equations at logarithmically-spaced co-location points <span class="math notranslate nohighlight">\(\xi\)</span>.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">scienceplots</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">astropy.units</span> <span class="k">as</span> <span class="nn">u</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">mticker</span>
<span class="kn">import</span> <span class="nn">matplotlib.colors</span> <span class="k">as</span> <span class="nn">mcolors</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.nn.utils</span> <span class="k">as</span> <span class="nn">nn_utils</span>
<span class="kn">import</span> <span class="nn">torch.nn.init</span> <span class="k">as</span> <span class="nn">init</span>

<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">astropy.io</span> <span class="kn">import</span> <span class="n">fits</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">matplotlib.cm</span> <span class="kn">import</span> <span class="n">ScalarMappable</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">Normalize</span><span class="p">,</span> <span class="n">ListedColormap</span><span class="p">,</span> <span class="n">BoundaryNorm</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1.inset_locator</span> <span class="kn">import</span> <span class="n">inset_axes</span><span class="p">,</span> <span class="n">mark_inset</span>
<span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">torch.func</span> <span class="kn">import</span> <span class="n">functional_call</span><span class="p">,</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">grad</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">trange</span><span class="p">,</span> <span class="n">tqdm</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;science&#39;</span><span class="p">);</span> <span class="n">fs</span><span class="o">=</span><span class="mi">15</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;text.usetex&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">DTYPE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>

<span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">data_folder_path</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">cwd</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s1">&#39;ml_astro&#39;</span> <span class="o">/</span> <span class="s1">&#39;chapter3&#39;</span> <span class="o">/</span> <span class="s1">&#39;data&#39;</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">solveLaneEmden</span><span class="p">(</span><span class="n">log_delta_xi</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">terminate</span> <span class="o">=</span> <span class="s1">&#39;firstzero&#39;</span><span class="p">):</span>

    <span class="n">delta_xi</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">log_delta_xi</span>

    <span class="c1"># Inner boundary condition</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">delta_xi</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">6</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="o">-</span><span class="n">delta_xi</span><span class="o">**</span><span class="mi">3</span><span class="o">/</span><span class="mi">3</span>

    <span class="n">ys</span>  <span class="o">=</span> <span class="p">[</span><span class="n">y0</span><span class="p">]</span>
    <span class="n">zs</span>  <span class="o">=</span> <span class="p">[</span><span class="n">z0</span><span class="p">]</span>
    <span class="n">xis</span> <span class="o">=</span> <span class="p">[</span><span class="n">delta_xi</span><span class="p">]</span>
    <span class="n">ycs</span> <span class="o">=</span> <span class="p">[</span><span class="n">y0</span><span class="p">]</span>
    <span class="n">zcs</span> <span class="o">=</span> <span class="p">[</span><span class="n">z0</span><span class="p">]</span>
    
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">y</span>  <span class="o">=</span>  <span class="n">ys</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>  <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">z</span>  <span class="o">=</span>  <span class="n">zs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span>  <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">xi</span> <span class="o">=</span> <span class="n">xis</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">xis</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">yc</span> <span class="o">=</span> <span class="n">ycs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">ycs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">zc</span> <span class="o">=</span> <span class="n">zcs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">zcs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1">## Primitive method</span>
        <span class="n">yi</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">delta_xi</span> <span class="o">*</span> <span class="n">z</span><span class="o">/</span><span class="n">xi</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">zi</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">delta_xi</span> <span class="o">*</span> <span class="o">-</span><span class="n">xi</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="n">n</span>

        <span class="c1">## Predictor-corrector technique</span>
        <span class="n">xii</span> <span class="o">=</span> <span class="n">xi</span> <span class="o">+</span> <span class="n">delta_xi</span>
        <span class="n">yci</span> <span class="o">=</span> <span class="n">yc</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta_xi</span> <span class="o">*</span> <span class="p">(</span><span class="n">z</span><span class="o">/</span><span class="n">xi</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">zi</span><span class="o">/</span><span class="n">xii</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">zci</span> <span class="o">=</span> <span class="n">zc</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta_xi</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">xi</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="n">n</span> <span class="o">-</span> <span class="n">xi</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">yi</span><span class="o">**</span><span class="n">n</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">terminate</span> <span class="o">==</span> <span class="s1">&#39;firstzero&#39;</span><span class="p">:</span>  
            <span class="k">if</span> <span class="p">(</span><span class="n">yci</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">):</span> <span class="k">break</span> <span class="c1"># Two conditions for generation, one to the first zero in theta</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="k">if</span> <span class="n">xii</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span> <span class="k">break</span> <span class="c1"># Another for a fixed coordinate xi</span>

        <span class="n">xis</span> <span class="o">+=</span> <span class="p">[</span><span class="n">xii</span><span class="p">]</span>
        <span class="n">ys</span>  <span class="o">+=</span> <span class="p">[</span><span class="n">yi</span><span class="p">]</span>
        <span class="n">zs</span>  <span class="o">+=</span> <span class="p">[</span><span class="n">zi</span><span class="p">]</span>
        <span class="n">ycs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">yci</span><span class="p">]</span>
        <span class="n">zcs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">zci</span><span class="p">]</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">xis</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]:</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">solveLaneEmden</span><span class="p">(</span><span class="n">log_delta_xi</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\xi$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">prop</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">fs</span><span class="o">-</span><span class="mi">3</span><span class="p">},</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">framealpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Lane-Emden Equation&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/84da4d2741f669661052a810c5bae636db749aaa7c3444e65c346e7c020b0212.png" src="../_images/84da4d2741f669661052a810c5bae636db749aaa7c3444e65c346e7c020b0212.png" />
</div>
</div>
<div class="note admonition">
<p class="admonition-title">Lane–Emden as a First-Order System</p>
<p>To make the numerical integration easier, the function <code class="docutils literal notranslate"><span class="pre">solveLaneEmden</span></code> introduces auxiliary variables:</p>
<div class="math notranslate nohighlight">
\[
z(\xi) \;=\; \xi^2 \frac{d\theta}{d\xi}, \quad \quad \quad y = \theta.
\]</div>
<p>This converts the second-order Lane-Emden equation into a system of <strong>two coupled first-order ODEs</strong>:</p>
<div class="math notranslate nohighlight">
\[
\frac{dy}{d\xi} = \frac{z}{\xi^2}, 
\qquad 
\frac{dz}{d\xi} = -\xi^2 y^n .
\]</div>
<p>This formulation avoids the singular form of the second derivative at <span class="math notranslate nohighlight">\(\xi = 0\)</span> and performs reasonably with stepwise numerical methods such as the predictor–corrector scheme as performed by the <code class="docutils literal notranslate"><span class="pre">solveLaneEmden</span></code> function.</p>
</div>
<div class="danger admonition">
<p class="admonition-title">Debugging your Physics Equation</p>
<p>What happens when a non-integer <span class="math notranslate nohighlight">\(n\)</span> (e.g., <span class="math notranslate nohighlight">\(n=1.5\)</span>) is used to solve the above equation using <code class="docutils literal notranslate"><span class="pre">solveLaneEmden</span></code>? Take note of any warning outputs from the Python interpreter, and log any intermediate outputs from the numerical solver. Why does the warning occur, and how does this affect the output solution?</p>
</div>
</section>
</section>
<section id="training-the-pinn">
<h2>Training the PINN<a class="headerlink" href="#training-the-pinn" title="Permalink to this headline">#</a></h2>
<p>We will use the Lane-Emden equation as an illustrative example for training a PINN using <strong>only a physics loss</strong>.</p>
<section id="setting-up-a-generator">
<h3>Setting up a Generator<a class="headerlink" href="#setting-up-a-generator" title="Permalink to this headline">#</a></h3>
<p>we first need to set up a generator that will feed in grids of <span class="math notranslate nohighlight">\(\xi\)</span> to the PINN. Compared to the plots above, we will generate up to a fixed <span class="math notranslate nohighlight">\(\xi\)</span>, instead of up to the first zero in <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LaneEmdenGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">solver</span><span class="p">,</span> <span class="n">log_delta_xi</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
                 <span class="n">generations_per_epoch</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">terminate</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_delta_xi</span> <span class="o">=</span> <span class="n">log_delta_xi</span> <span class="c1"># Logarithmic spacing of xi in the grid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">terminate</span> <span class="o">=</span> <span class="n">terminate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>  <span class="c1"># How many grids per batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generations_per_epoch</span> <span class="o">=</span> <span class="mi">128</span>   <span class="c1"># How many batches per epoch</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">xisvec</span><span class="p">,</span> <span class="n">ycsvec</span><span class="p">,</span> <span class="n">ennevec</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">xis</span><span class="p">,</span> <span class="n">ycs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_delta_xi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">terminate</span><span class="p">)</span>
            <span class="n">xis</span><span class="p">,</span> <span class="n">ycs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xis</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">ycs</span><span class="p">))</span>
            
            <span class="n">xisvec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xis</span><span class="p">))</span>
            <span class="n">ycsvec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">ycs</span><span class="p">)))</span>
            <span class="n">ennevec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">xis</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

        <span class="n">tuple_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ennevec</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ycsvec</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">xisvec</span><span class="p">)</span> <span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="n">tuple_set</span> <span class="o">=</span> <span class="n">tuple_set</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">tuple_set</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
            
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tuple_set</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generations_per_epoch</span>
</pre></div>
</div>
</div>
</div>
<p>The generator <code class="docutils literal notranslate"><span class="pre">LaneEmdenGenerator</span></code> returns a <span class="math notranslate nohighlight">\(N \times 3\)</span> vector comprising the following:</p>
<ul class="simple">
<li><p>An <span class="math notranslate nohighlight">\(N \times 1\)</span> array of polytropic indices <span class="math notranslate nohighlight">\(n\)</span>, fixed for the problem.</p></li>
<li><p>An <span class="math notranslate nohighlight">\(N \times 1\)</span> array of <span class="math notranslate nohighlight">\(\theta\)</span> values. These will <strong>not</strong> be explicitly used to solve the PINN in this example.</p></li>
<li><p>An <span class="math notranslate nohighlight">\(N \times 1\)</span> array of <span class="math notranslate nohighlight">\(\xi\)</span> values, as co-location (grid) points.</p></li>
</ul>
</section>
<section id="defining-the-networks">
<h3>Defining the Networks<a class="headerlink" href="#defining-the-networks" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="c1">#### A simple multi-layer perceptron ###</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">()):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="c1"># Glorot Uniform initialization</span>
            <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">linear_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">NN_Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">branch_layers</span><span class="p">,</span> <span class="n">trunk_layers</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NN_Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">branch_net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">branch_layers</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trunk_net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">trunk_layers</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="mf">1.25e-5</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_log</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_operator_log</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_physics_log</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">single</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

        <span class="c1">## Use single = True in the scenario you need evaluation at a single colocation point (e.g., at boundaries)</span>
        
        <span class="k">if</span> <span class="n">single</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">branch_net</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">T</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trunk_net</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">single</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="deeponet">
<a class="reference internal image-reference" href="../_images/deeponet.png"><img alt="../_images/deeponet.png" src="../_images/deeponet.png" style="width: 500px; height: 370px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 40 </span><span class="caption-text">Schematic of a Deep Operator Network (DeepONet).</span><a class="headerlink" href="#deeponet" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>In this example, the type of network we will use is inspired by Deep Operator Networks <a class="reference external" href="https://arxiv.org/abs/1910.0319">(DeepONets)</a>. A DeepONet learns a mapping from a function input <span class="math notranslate nohighlight">\(u\)</span> to a predicted function value at location <span class="math notranslate nohighlight">\(y\)</span>. It comprises two components:</p>
<ul class="simple">
<li><p><strong>Branch Net <span class="math notranslate nohighlight">\(B(u)\)</span>:</strong> Encodes information about the input function <span class="math notranslate nohighlight">\(u\)</span>. In our Lane-Emden equation, <span class="math notranslate nohighlight">\(u=n\)</span>.</p></li>
<li><p><strong>Trunk Net <span class="math notranslate nohighlight">\(T(y)\)</span>:</strong> Encodes information about the coordinate or location <span class="math notranslate nohighlight">\(y\)</span>. In our Lane-Emden equation, <span class="math notranslate nohighlight">\(y=\xi\)</span></p></li>
</ul>
<p>Both Branch and Trunk nets are Multilayer Perceptrons.</p>
<p>The final prediction is given by the inner product</p>
<div class="math notranslate nohighlight">
\[
\hat{f}(u,y) \;=\; \sum_{j=1}^{p} B_j(u)\,T_j(y),
\]</div>
<p>i.e., a weighted combination of branch and trunk features.</p>
<div class="tip admonition">
<p class="admonition-title">Why a DeepONet?</p>
<p>Unlike a standard MLP, which directly maps <span class="math notranslate nohighlight">\((u,y) \mapsto f(u,y)\)</span>, a DeepONet factorizes the prediction:</p>
<div class="math notranslate nohighlight">
\[
\hat{f}(u,y) \;=\; \sum_{j=1}^{p} B_j(u)\,T_j(y),
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B(u)\)</span> encodes the input function (branch net),</p></li>
<li><p><span class="math notranslate nohighlight">\(T(y)\)</span> encodes the evaluation coordinate (trunk net).</p></li>
</ul>
<p>Once trained, the model can evaluate <span class="math notranslate nohighlight">\(f(u,y)\)</span> at <strong>new values of <span class="math notranslate nohighlight">\(y\)</span></strong>, even if they were not explicitly included in the training set.<br />
In other words, DeepONets generalize across the domain of <span class="math notranslate nohighlight">\(y\)</span>, turning the network into an <strong>operator approximator</strong> rather than a pointwise regressor.</p>
</div>
</section>
<section id="losses-physics-constraint">
<h3>Losses – Physics Constraint<a class="headerlink" href="#losses-physics-constraint" title="Permalink to this headline">#</a></h3>
<p>Next, we will define functions corresponding to equations <a class="reference internal" href="#equation-eq-lane-emden">(34)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_sample_ode_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="c1">### Computes the residual of the equation ###</span>
    
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">ddξ_ξ2_dθdξ</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">ξ</span><span class="p">:</span> <span class="p">(</span><span class="n">ξ</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">ξ</span><span class="p">)</span>  <span class="c1"># LHS</span>
    <span class="n">ξ2_θn</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span> <span class="p">(</span><span class="n">ξ</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">pred</span> <span class="o">**</span> <span class="n">n</span> <span class="p">)</span>  <span class="p">)</span>  <span class="c1">## RHS</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">ddξ_ξ2_dθdξ</span> <span class="o">-</span> <span class="n">ξ2_θn</span>
    
    <span class="k">return</span> <span class="n">residual</span>

<span class="k">def</span> <span class="nf">compute_ode_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ξ</span> <span class="o">=</span> <span class="n">ξ</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">compute_sample_ode_loss</span><span class="p">,</span> <span class="n">in_dims</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Batched Gradients</p>
<p>In PINNs, we often need to evaluate PDE residuals at many collocation points.</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">grad</span></code></strong> computes derivatives of the network output with respect to its inputs.<br />
Nested calls allow higher-order derivatives (e.g. the second derivative in the Lane–Emden equation).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">vmap</span></code></strong> vectorizes these gradient calculations across a batch of collocation points, replacing an explicit Python for-loop with an efficient parallel computation.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">in_dims=(None,</span> <span class="pre">0,</span> <span class="pre">0)</span></code> applies to each input argument, i.e., <code class="docutils literal notranslate"><span class="pre">(model,</span> <span class="pre">n,</span> <span class="pre">ξ)</span></code>. This means <code class="docutils literal notranslate"><span class="pre">model</span></code> is not vectorized, while <code class="docutils literal notranslate"><span class="pre">n</span></code> and <code class="docutils literal notranslate"><span class="pre">ξ</span></code> are vectorized over the first axis.</p></li>
</ul>
</li>
</ul>
<p>This is in opposition to <code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code> alone, which does not return per-sample gradients in a batch. Therefore, the following code allows the ODE residual for an entire batch of inputs in one pass:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">residuals</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_sample_ode_loss</span><span class="p">)(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="losses-boundary-conditions">
<h3>Losses – Boundary Conditions<a class="headerlink" href="#losses-boundary-conditions" title="Permalink to this headline">#</a></h3>
<p>We now define the losses for the boundary conditions as defined in <a class="reference internal" href="#equation-boundary-lane-emden">(35)</a>.</p>
<p>For the condition of <span class="math notranslate nohighlight">\(\frac{d\theta}{d\xi}=0\)</span> for <span class="math notranslate nohighlight">\(\xi=0\)</span>, see that:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">compute_sample_innergrad_loss</span></code> returns the <strong>gradient</strong> <span class="math notranslate nohighlight">\(\frac{d\theta}{d\xi}\)</span>.</p></li>
<li><p>The MSE loss is calculated with respect to the zero vector (<code class="docutils literal notranslate"><span class="pre">torch.zeros_like(inner_grad)</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### dθdξ(ξ=0) = 0 ###</span>
<span class="k">def</span> <span class="nf">compute_sample_innergrad_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">grad</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_inner_grad_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ξ</span> <span class="o">=</span> <span class="n">ξ</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span><span class="o">*</span><span class="mf">0.</span>  <span class="c1">### ξ=0 </span>
    <span class="n">inner_grad</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">compute_sample_innergrad_loss</span><span class="p">,</span> <span class="n">in_dims</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span>
    <span class="k">return</span>  <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">inner_grad</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">inner_grad</span><span class="p">))</span> <span class="c1">### dθ/dξ=0 </span>
</pre></div>
</div>
</div>
</div>
<p>For the condition of <span class="math notranslate nohighlight">\(\theta=0\)</span> for <span class="math notranslate nohighlight">\(\xi=1\)</span>, see that:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">compute_sample_innerbc_loss</span></code> returns the <strong>function value</strong> <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>The MSE loss is calculated with respect to a vector of ones (<code class="docutils literal notranslate"><span class="pre">torch.ones_like(inner_bc_pred)</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### θ(ξ=0) = 1 ###</span>
<span class="k">def</span> <span class="nf">compute_sample_innerbc_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="n">pred_at_boundary</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pred_at_boundary</span>

<span class="k">def</span> <span class="nf">compute_inner_bc_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ξ</span> <span class="o">=</span> <span class="n">ξ</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span><span class="o">*</span><span class="mf">0.</span>  <span class="c1">### ξ=0 </span>
    <span class="n">inner_bc_pred</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">compute_sample_innerbc_loss</span><span class="p">,</span> <span class="n">in_dims</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span>
    <span class="k">return</span>  <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">inner_bc_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">inner_bc_pred</span><span class="p">))</span>  <span class="c1">### θ=1 </span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-loop">
<h3>Training Loop<a class="headerlink" href="#training-loop" title="Permalink to this headline">#</a></h3>
<p>Putting it altogether, we have the following for the training step:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">boundary_loss</span><span class="p">,</span> <span class="n">deriv_loss</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="n">ode_loss</span> <span class="o">=</span> <span class="n">compute_ode_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span>  <span class="c1"># Physics </span>
    <span class="n">deriv_loss</span> <span class="o">=</span> <span class="n">compute_inner_grad_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span>  <span class="c1"># Boundary Condition for Derivative</span>
    <span class="n">boundary_loss</span> <span class="o">=</span> <span class="n">compute_inner_bc_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ξ</span><span class="p">)</span> <span class="c1"># Boundary Condition for Value</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">ode_loss</span> <span class="o">+</span> <span class="mf">1e4</span><span class="o">*</span><span class="n">boundary_loss</span> <span class="o">+</span> <span class="mf">1e4</span><span class="o">*</span><span class="n">deriv_loss</span>  <span class="c1"># weighting BC by an arbitrary factor</span>
    <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ode_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">boundary_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">deriv_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>and the following function <code class="docutils literal notranslate"><span class="pre">train</span></code> for the training loop. A function <code class="docutils literal notranslate"><span class="pre">visualize_example</span></code> is first defined to allow us to keep track of the PINN predictions with those from numerical integration during the training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_example</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">operator_dataloader</span><span class="p">,</span> <span class="n">iteration</span><span class="p">):</span>

    <span class="c1">### Comparing the Numerical Integration with Predictions from the PINN ###</span>
    
    <span class="n">xisvec</span><span class="p">,</span> <span class="n">ycsvec</span><span class="p">,</span> <span class="n">ennevec</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">xis</span><span class="p">,</span> <span class="n">ycs</span> <span class="o">=</span> <span class="n">operator_dataloader</span><span class="o">.</span><span class="n">solver</span><span class="p">(</span><span class="n">operator_dataloader</span><span class="o">.</span><span class="n">log_delta_xi</span><span class="p">,</span> <span class="n">operator_dataloader</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">xis</span><span class="p">,</span> <span class="n">ycs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xis</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">ycs</span><span class="p">))</span>

    <span class="n">xisvec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xis</span><span class="p">))</span>
    <span class="n">ycsvec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">ycs</span><span class="p">)))</span>
    <span class="n">ennevec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">xis</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">)</span>

    <span class="n">tuple_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ennevec</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ycsvec</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">xisvec</span><span class="p">)</span> <span class="p">))</span><span class="o">.</span><span class="n">T</span>
    <span class="n">tuple_set</span> <span class="o">=</span> <span class="n">tuple_set</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">tuple_set</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
    <span class="n">tuple_set_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tuple_set</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tuple_set_tensor</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">tuple_set_tensor</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tuple_set</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">tuple_set</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Manual&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tuple_set_tensor</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">pred</span><span class="p">[:]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;PINN&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;n: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">, Iteration: </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.65</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span>
             <span class="n">s</span><span class="o">=</span> <span class="s1">&#39;Lane-Emden Eqn.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">+</span><span class="sa">r</span><span class="s2">&quot;$\frac</span><span class="si">{1}</span><span class="s2">{\xi^2} \frac</span><span class="si">{d}</span><span class="s2">{d\xi} \left( \xi^2 \frac{d\theta}{d\xi} \right) + \theta^n = 0$&quot;</span> <span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">transAxes</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ξ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="n">fs</span><span class="o">-</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">operator_dataloader</span><span class="p">,</span> <span class="n">nIter</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span> <span class="c1">#nIter is number of training epochs</span>
        <span class="n">boundary_loss_vec</span> <span class="o">=</span> <span class="p">[]</span> 
        <span class="n">derivative_loss_vec</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ode_loss_vec</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">operator_dataloader</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pbar</span><span class="p">,</span> <span class="n">operator_dataloader</span><span class="p">):</span>

            <span class="n">n_batch</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">ξ_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">_</span><span class="p">,</span> <span class="n">batch</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">ode_loss_value</span><span class="p">,</span> <span class="n">boundary_loss_value</span><span class="p">,</span> <span class="n">derivative_loss_value</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">n_batch</span><span class="p">,</span> <span class="n">ξ_batch</span><span class="p">)</span>

            <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;Boundary Loss&#39;</span><span class="p">:</span> <span class="n">boundary_loss_value</span><span class="p">,</span>
                              <span class="s1">&#39;Derivative Loss&#39;</span><span class="p">:</span> <span class="n">derivative_loss_value</span><span class="p">,</span>
                              <span class="s1">&#39;ODE Loss&#39;</span><span class="p">:</span> <span class="n">ode_loss_value</span><span class="p">,</span>
                             <span class="s1">&#39;learning rate&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]})</span>

            <span class="n">boundary_loss_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">boundary_loss_value</span><span class="p">)</span>
            <span class="n">derivative_loss_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">derivative_loss_value</span><span class="p">)</span>
            <span class="n">ode_loss_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ode_loss_value</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average ODE Loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ode_loss_vec</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">Average Boundary Loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boundary_loss_vec</span><span class="p">)</span><span class="si">}</span><span class="se">\n\</span>
<span class="s1">        Average Derivative Loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">derivative_loss_vec</span><span class="p">)</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\</span>
<span class="s1">              Average Total Loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ode_loss_vec</span><span class="p">)</span> <span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boundary_loss_vec</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">derivative_loss_vec</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="n">visualize_example</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">operator_dataloader</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we initialize the generator and model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">LaneEmdenGenerator</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="n">solveLaneEmden</span><span class="p">,</span> <span class="n">log_delta_xi</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1">## MLP Architecture ##</span>
<span class="n">num_neurons</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">n_dim</span> <span class="o">=</span> <span class="n">ξ_dim</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

<span class="n">branch_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_neurons</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_layers</span>
<span class="n">trunk_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">ξ_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_neurons</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_layers</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NN_Model</span><span class="p">(</span><span class="n">branch_layers</span><span class="p">,</span> <span class="n">trunk_layers</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And finally, we run the <code class="docutils literal notranslate"><span class="pre">train</span></code> function with the previously defined generator of Lane-Emden equations, <code class="docutils literal notranslate"><span class="pre">gen</span> <span class="pre">=</span> <span class="pre">LaneEmdenGenerator</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">gen</span><span class="p">,</span> <span class="n">nIter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 0
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2f5c393e7e9d47438719bec61ca80bbf", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average ODE Loss: 24.122644430177534
Average Boundary Loss: 0.2638139855922991
        Average Derivative Loss: 0.0010952500281471785,
              Average Total Loss: 24.38755366579798
</pre></div>
</div>
<img alt="../_images/805ad655871d3a5e23412284396d0f61eefc06cc0c94228ed29eb13ff264d9fb.png" src="../_images/805ad655871d3a5e23412284396d0f61eefc06cc0c94228ed29eb13ff264d9fb.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 1
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "414a3af7daae418a9b8ea68369402e85", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average ODE Loss: 3.7149846265878783
Average Boundary Loss: 2.8962180221825727e-06
        Average Derivative Loss: 1.2901252987648375e-05,
              Average Total Loss: 3.7150004240588883
</pre></div>
</div>
<img alt="../_images/022122da4b0323830b0125a9eece5d4764a5920179e51a5817f539c0d03d57d8.png" src="../_images/022122da4b0323830b0125a9eece5d4764a5920179e51a5817f539c0d03d57d8.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 2
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0ada13228e5a4bccac753abf094bc9c1", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average ODE Loss: 1.52657016930806
Average Boundary Loss: 3.904653945646213e-07
        Average Derivative Loss: 2.658476285244073e-06,
              Average Total Loss: 1.5265732182497398
</pre></div>
</div>
<img alt="../_images/beaf91932ce32b96897d9cbf515ed6698318f3de08c7fee22a61377bd8a57247.png" src="../_images/beaf91932ce32b96897d9cbf515ed6698318f3de08c7fee22a61377bd8a57247.png" />
</div>
</div>
<p>The PINN may take some time to fully converge, but the following demonstrates the convergence of the PINN to the numerical solution.</p>
<p><img alt="" src="https://raw.githubusercontent.com/mtyhon/astropinn/main/images/laneemden_n3_downsample10.gif" /></p>
</section>
</section>
<section id="other-odes-in-astrophysics">
<h2>Other ODEs in Astrophysics<a class="headerlink" href="#other-odes-in-astrophysics" title="Permalink to this headline">#</a></h2>
<p>Many physical systems in astrophysics (and physics in general) are described by systems of ODEs. The following are several examples</p>
<section id="example-1-planetary-motion">
<h3>Example 1 - Planetary Motion<a class="headerlink" href="#example-1-planetary-motion" title="Permalink to this headline">#</a></h3>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Kepler_problem">Kepler problem</a> describes the motion of a secondary body (planet, asteroid, comet, etc.) around a primary body.  In the orbital (<span class="math notranslate nohighlight">\(x-y\)</span>) plane, the total energy of the of the system is described by its Hamiltonian <span class="math notranslate nohighlight">\(H_{\mathrm{Kepler}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
H_{\mathrm{Kepler}} = \frac{1}{2\mu}(p_x^2+p_y^2)-\frac{\mu}{\sqrt{x^2+y^2}},
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu = G(m_1+m_2)\)</span> is the gravitational parameter,</p></li>
<li><p><span class="math notranslate nohighlight">\(p_x, p_y\)</span> are the canonical momenta,</p></li>
<li><p><span class="math notranslate nohighlight">\((x,y)\)</span> are the relative coordinates of the secondary body.</p></li>
</ul>
<p>Using Hamilton’s equations, the equations of motion are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\dot{x} &amp;= u, \\
\dot{y} &amp;= v, \\
\dot{u} &amp;= -\frac{\mu x}{(x^2+y^2)^{3/2}}, \\
\dot{v} &amp;= -\frac{\mu y}{(x^2+y^2)^{3/2}},
\end{aligned}
\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> are, respectively, the <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> components of the velocity, such that <span class="math notranslate nohighlight">\(p_x = \mu u\)</span> and <span class="math notranslate nohighlight">\(p_y = \mu v\)</span>.</p>
<div class="note admonition">
<p class="admonition-title">Exercise: Kepler problem PINN</p>
<p>Write a Python function that computes the <strong>physics loss</strong> for a PINN solving the Kepler problem.<br />
Your function should:</p>
<ol class="arabic simple">
<li><p>Take as input the predicted states <span class="math notranslate nohighlight">\((x,y,u,v)\)</span> at collocation points in time.</p></li>
<li><p>Use <strong>batched</strong> automatic differentiation to compute time derivatives <span class="math notranslate nohighlight">\((\dot{x}, \dot{y}, \dot{u}, \dot{v})\)</span>.</p></li>
<li><p>Compute the residuals of the four Kepler ODEs above.</p></li>
<li><p>Return the mean squared residual as the physics loss.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kepler_physics_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">μ</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    model: neural network predicting [x, y, u, v] as a function of time t. Output is of dimensionality $N\times 4$</span>
<span class="sd">    t: tensor of collocation times of dimensionality $N\times 1$</span>
<span class="sd">    μ: gravitational parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. Predict states from the model</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    
    <span class="c1"># 2. Compute time derivatives using torch.func.grad</span>
    <span class="n">dx_dt</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">dy_dt</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">du_dt</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">dv_dt</span> <span class="o">=</span> <span class="o">...</span>
    
    <span class="c1"># 3. Define residuals according to the equations of motion</span>
    <span class="n">res_x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">res_y</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">res_u</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">res_v</span> <span class="o">=</span> <span class="o">...</span>
    
    <span class="c1"># 4. Return physics loss</span>
    <span class="n">loss_phys</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">loss_phys</span>
</pre></div>
</div>
</div>
</section>
<section id="example-2-friedmann-acceleration-equation">
<h3>Example 2 - Friedmann Acceleration Equation<a class="headerlink" href="#example-2-friedmann-acceleration-equation" title="Permalink to this headline">#</a></h3>
<p>For a flat FLRW universe <span class="math notranslate nohighlight">\((k=0)\)</span> containing matter and a cosmological constant <span class="math notranslate nohighlight">\(\Lambda\)</span>, the evolution of the universe with time <span class="math notranslate nohighlight">\(t\)</span> can be written as <span class="math notranslate nohighlight">\(\tau = H_0 t\)</span> where <span class="math notranslate nohighlight">\(H_0\)</span> is the Hubble constant. The universe’s expansion can be described by the (dimensionless) <strong>Friedmann acceleration equation</strong>:</p>
<div class="math notranslate nohighlight">
\[
\frac{a''(\tau)}{a(\tau)} 
= \overbrace{-\frac{1}{2}\frac{\Omega_m}{a(\tau)^3}}^{\text{Gravitational deceleration from matter}} \overbrace{+ \Omega_\Lambda}^{\text{Accelerated expansion due to dark energy}},
\]</div>
<p>which forms the following second-order ODE:</p>
<div class="math notranslate nohighlight">
\[
a''(\tau)
= -\frac{1}{2}\frac{\Omega_m}{a(\tau)^2} + \Omega_\Lambda a(\tau),
\]</div>
<p>where primes denote derivatives with respect to <span class="math notranslate nohighlight">\(\tau\)</span>. The scale factor <span class="math notranslate nohighlight">\(a(\tau)\)</span> describes <strong>how distances in the universe expand with time</strong> as <strong>first slowing down</strong> (matter-dominated) before being <strong>accelerated</strong> later on (dark energy-dominated). Here, <span class="math notranslate nohighlight">\(\Omega_m\)</span> is the present-day matter density parameter, while <span class="math notranslate nohighlight">\(\Omega_\Lambda\)</span> is the present-day dark energy density parameter. The boundary conditions for the ODE are the following:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a(0) = 0\)</span> (Big Bang),</p></li>
<li><p><span class="math notranslate nohighlight">\(a(\tau_0) = 1\)</span> (present day),</p></li>
<li><p>optionally <span class="math notranslate nohighlight">\(\,a'(\tau_0)=1\)</span> (since time is scaled by <span class="math notranslate nohighlight">\(H_0^{-1}\)</span>).</p></li>
</ul>
<div class="exercise admonition">
<p class="admonition-title">Exercise: The Friedmann Acceleration Equation</p>
<p>Implement a physics-informed loss for a PINN that learns the scale factor <span class="math notranslate nohighlight">\(a(\tau)\)</span>.
Your function should:</p>
<ol class="arabic simple">
<li><p>Predict <span class="math notranslate nohighlight">\(a(\tau)\)</span> at collocation points using the neural network.</p></li>
<li><p>Use <strong>batched</strong> automatic differentiation to compute the second derivative <span class="math notranslate nohighlight">\(a''(\tau)\)</span>.</p></li>
<li><p>Impose boundary conditions from <strong>batched</strong> first derivatives <span class="math notranslate nohighlight">\(a'(\tau)\)</span> and <strong>batched</strong> predictions <span class="math notranslate nohighlight">\(a(\tau)\)</span>.</p></li>
<li><p>Form the residuals and return the mean squared residual as the physics loss.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">friedmann_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">τ</span><span class="p">,</span> <span class="n">Ωm</span><span class="p">,</span> <span class="n">ΩΛ</span><span class="p">,</span> <span class="n">τ0</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>

    <span class="c1"># 1. $a(\tau)$</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">τ</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="c1"># 2. First and second derivatives</span>
    <span class="n">da_dτ</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">d2a_dτ2</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># 3. Define residuals from physics loss</span>
    <span class="n">phys_residual</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># 4. Define residuals from boundary conditions loss</span>
    <span class="n">a0</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">a_today</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">adot_today</span> <span class="o">=</span> <span class="o">...</span>
    
    <span class="n">bc_residual</span> <span class="o">=</span> <span class="o">...</span>
    
    <span class="c1"># 4. Return loss as combination of residuals</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>

    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">The Dimensionless Form of the Friedmann Acceleration Equation</p>
<p>The Friedmann acceleration equation in cosmic time is:</p>
<div class="math notranslate nohighlight">
\[
\frac{\ddot{a}(t)}{a(t)} 
= -\frac{4\pi G}{3}\rho_m(t) + \frac{\Lambda}{3}.
\]</div>
<p>Here <span class="math notranslate nohighlight">\(a(t)\)</span> is the scale factor, and the present epoch is defined as <span class="math notranslate nohighlight">\(t=t_0\)</span>, such that <span class="math notranslate nohighlight">\(a(t)\)</span> is normalized so that <span class="math notranslate nohighlight">\(a(t_0)=1\)</span> today. We note that the Hubble constant is</p>
<div class="math notranslate nohighlight">
\[
H_0 \;\equiv\; \frac{\dot{a}(t_0)}{a(t_0)},
\]</div>
<p>and we define the dimensionless time as <span class="math notranslate nohighlight">\(\tau \;=\; H_0\,t\)</span>, such that:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\frac{d^2}{dt^2} &amp;= H_0^2 \frac{d^2}{d\tau^2}.
\end{aligned}
\]</div>
<p>Next, we define the critical density:</p>
<div class="math notranslate nohighlight">
\[
\rho_c \;=\; \frac{3H_0^2}{8\pi G},
\]</div>
<p>and density parameters</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\Omega_m &amp;= \frac{\rho_{m,0}}{\rho_c},\\ 
\Omega_\Lambda &amp;= \frac{\Lambda}{3H_0^2}.
\end{aligned}
\end{split}\]</div>
<p>From energy conservation (the cosmological fluid equation):</p>
<div class="math notranslate nohighlight">
\[
\dot{\rho} + 3\frac{\dot{a}}{a}(\rho + p/c^2) = 0,
\]</div>
<p>where for pressureless matter <span class="math notranslate nohighlight">\((p=0)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\rho_m(t) = \rho_{m,0}\,a(t)^{-3}.
\]</div>
<p>Substituting the above into the acceleration equation gives:</p>
<div class="math notranslate nohighlight">
\[
\frac{a''(\tau)}{a(\tau)} 
= -\frac{1}{2}\frac{\Omega_m}{a(\tau)^3} + \Omega_\Lambda,
\]</div>
<p>where primes denote derivatives with respect to <span class="math notranslate nohighlight">\(\tau\)</span>.</p>
<p>Because time is scaled by <span class="math notranslate nohighlight">\(H_0^{-1}\)</span>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a(0)=0\)</span> (Big Bang)</p></li>
<li><p><span class="math notranslate nohighlight">\(a(\tau_0)=1\)</span> (Present day, normalized)</p></li>
<li><p><span class="math notranslate nohighlight">\(a'(\tau_0)=1\)</span> (Since <span class="math notranslate nohighlight">\(\dot{a}(t_0)=H_0\)</span>).</p></li>
</ul>
<p>See also: <a class="reference external" href="https://people.ast.cam.ac.uk/~pettini/Intro%20Cosmology/Lecture04.pdf">Lecture Notes on Cosmology</a></p>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="tabular-4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Catalogue Data Part 2: <em>Finding Clusters and Overdensities</em></p>
      </div>
    </a>
    <a class="right-next"
       href="../chapter4/section_intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Images</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formulation">Formulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-the-lane-emden-equation">Example: The Lane-Emden Equation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-lane-emden-equations">Generating Lane-Emden Equations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-pinn">Training the PINN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-a-generator">Setting up a Generator</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-networks">Defining the Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losses-physics-constraint">Losses – Physics Constraint</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losses-boundary-conditions">Losses – Boundary Conditions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-loop">Training Loop</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-odes-in-astrophysics">Other ODEs in Astrophysics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1-planetary-motion">Example 1 - Planetary Motion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-friedmann-acceleration-equation">Example 2 - Friedmann Acceleration Equation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Marc Hon
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>